---
title: "Modelando con R"
author: "David Suárez <david.suarez@yahoo.com>"
date: "28 de abril de 2018"
output: html_document
---

# Modelación

En general hay dos pasos en todo proceso de modelación:

1.  Escoges una familia de modelos `y = a_1 * x + a_2` o `y = a_1 * x ^ a_2`.

1.  Generas un modelo ajustado, como `y = 3 * x + 7` o `y = 9 * x ^ 2`, donde `a_1` y `a_2` toman ciertos valores.

A través de este proceso obtendremos el mejor modelo, pero no necesariamente el verdadero. Como dice un aforismo de George Box:

> All models are wrong, but some are useful.

La cita completa es:

> Now it would be very remarkable if any system existing in the real world 
> could be exactly represented by any simple model. However, cunningly chosen 
> parsimonious models often do provide remarkably useful approximations. For 
> example, the law PV = RT relating pressure P, volume V and temperature T of 
> an "ideal" gas via a constant R is not exactly true for any real gas, but it 
> frequently provides a useful approximation and furthermore its structure is 
> informative since it springs from a physical view of the behavior of gas 
> molecules.
> 
> For such a model there is no need to ask the question "Is the model true?". 
> If "truth" is to be the "whole truth" the answer must be "No". The only 
> question of interest is "Is the model illuminating and useful?".

La meta de la modelación no es descubrir la verdad, sino obtener una buena aproximación que sea útil. 

### Prerequisitos: modelr

```{r setup, message = FALSE}
library(tidyverse)

library(modelr)
options(na.action = na.warn)
```

## Un modelo simple

modelr::sim1

```{r}
ggplot(sim1, aes(x, y)) + 
  geom_point()
```

Pareciera haber un patrón en nuestros datos, y pareciera ser lineal: `y = a_0 + a_1 * x`.

```{r}
models <- tibble(
  a1 = runif(250, -20, 40),
  a2 = runif(250, -5, 5)
)

ggplot(sim1, aes(x, y)) + 
  geom_abline(aes(intercept = a1, slope = a2), data = models, alpha = 1/4) +
  geom_point() 
```

Pero, qué tan bueno es cada uno de esos modelos:

```{r, echo = FALSE}
dist1 <- sim1 %>% 
  mutate(
    dodge = rep(c(-1, 0, 1) / 20, 10),
    x1 = x + dodge,
    pred = 7 + x1 * 1.5
  )

ggplot(dist1, aes(x1, y)) + 
  geom_abline(intercept = 7, slope = 1.5, colour = "grey40") +
  geom_point(colour = "grey40") +
  geom_linerange(aes(ymin = y, ymax = pred), colour = "#3366FF") 
```

Para calcular esas distancias, requerimos convertir nuestra familia de modelos en una función:

```{r}
model1 <- function(a, data) {
  a[1] + data$x * a[2]
}
model1(c(7, 1.5), sim1)
```

Una forma de calcular el error de nuestro modelo es estimando la diferencia entre los valores predichos por éste y los datos originales:

```{r}
sim1$y - model1(c(7, 1.5), sim1)
```

Para hacer más fácil este procedimiento, podemos crear una función que haga la misma resta. Le pasamos a esta función un vector con los dos parámetros de nuestro modelo y los datos que estamos intentando modelar:

```{r}
distancia <- function(param, datos) {datos$y-model1(param, datos)}

distancia(c(1,1.5), sim1)
distancia(c(7,1.5), sim1)
```

Una forma de comparar los parámetros que generan las menores distancias entre las predicciones y los datos sería usando el dataframe `modelos` que generamos anteriormente al azar:

```{r}
distancia(unlist(models[1,]), sim1)
```

Pero incluso mejor sería emplear una malla regular, que explore todo un espacio de datos, dentro del cual pensamos que están las mejores combinaciones de parámetros:

```{r}
grid <- expand.grid(
a1 = seq(-5, 5, length = 100),
a2 = seq(1, 3, length = 100)
)
```

Otro cambio conveniente es que para comparar distintos parámetros sería mucho más fácil si las diferencias entre las predicciones y los datos pudieran resumirse en un solo valor. Para esto es muy útil modificar nuestra función de distancia de la siguiente manera:

```{r}
distancia1 <- function(mod, data) {
  diff <- data$y - model1(mod, data)
  sqrt(mean(diff ^ 2))
}
```
Usando esta función es muy fácil agregar una nueva columna a `grid` que contenga las distancias para cada pareja de parámetros:
```{r}
grid$dist <- sapply(1:nrow(grid), function(row) sd(distancia(c(grid$a1[row], grid$a2[row]), sim1)))
```

Ahora, podemos graficar los diez mejores resultados, esto es, aquellos que tienen la menor distancia con respecto a los datos:

```{r}
ggplot(sim1, aes(x, y)) + geom_abline(aes(intercept = a1, slope = a2, color=dist), data = head(arrange(grid, dist), 10), alpha = 1/4) +   geom_point()
```

Aunque este procedimiento es correcto, incluso mejor sería aprovechar que en R existe una función `optim` que nos permite optimizar (maximizar o minimizar el resultado de una función):

```{r}
(best <- optim(c(0, 0), distancia1, data = sim1))
```

De acuerdo al resultado arrojado por esta función, los mejores valores para nuestros dos parámetros son: `{r}best$par`

Ahora bien, R incluye una función específica para tratar este problema cuando estamos trabajando con modelos lineales, pero para esto necesitamos especificar los modelos usando una sintaxis especial en R, empleando el operador de fórmulas: `~`, así, nuestro modelo se puede especificar simplemente usando la expresión `y ~ x`. `lm()` solamente requiere que especifiquemos el modelo y que le pasemos los datos con respecto a los cuales vamos a ajustar ese modelo:

```{r}
sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
summary(sim1_mod)
```
